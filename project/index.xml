<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Jessica Bourgin</title>
    <link>https://jbourgin.github.io/project/</link>
      <atom:link href="https://jbourgin.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 18 Mar 2020 10:59:18 +0100</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Projects</title>
      <link>https://jbourgin.github.io/project/</link>
    </image>
    
    <item>
      <title>Emotional attention in Alzheimer&#39;s disease</title>
      <link>https://jbourgin.github.io/project/emotional/</link>
      <pubDate>Wed, 18 Mar 2020 10:59:18 +0100</pubDate>
      <guid>https://jbourgin.github.io/project/emotional/</guid>
      <description>&lt;p&gt;Alzheimer&amp;rsquo;s Disease (AD) is a complex neurodegenerative pathology involving large brain alterations and the emergence of cognitive and behavioral symptoms that impair daily life. Even now, AD is difficult to diagnose precisely, notably because of the low-specificity of its main characteristics (i.e., memory symptoms and hippocampal atrophy). The systematic assessment of brain alterations that occur during the first stages of AD showed the existence of amygdala atrophy, which could lead to disruptions in emotional processing.&lt;/p&gt;
&lt;p&gt;In this project, we conduct paradigms involving emotional attention, in other words attentional processes directed toward emotional or neutral stimuli, which may be disrupted in patients with amygdala lesions.&lt;/p&gt;
&lt;p&gt;We already conducted two eye-tracking paradigms (i.e., eye movements recording) involving visual search and pro-saccade/anti-saccade tasks to get a fine analysis of attentional processes. The results of these two studies suggest that patients with AD present alterations of early emotional attention, which is involved in facilitating orienting toward emotional information.&lt;/p&gt;
&lt;p&gt;Using a neuroimaging analysis of structural and functional connectivity, we highlighted alterations in neural networks (including the amygdala) involved in attentional and emotional processes.&lt;/p&gt;
&lt;p&gt;Finally, we are currently conducting a neuroimaging study specifically exploring correlations between emotional attention processes and alterations in the corresponding neural network. Information regarding this paradigm can be found 
&lt;a href=&#34;https://github.com/jbourgin/ATEMMA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multimodal neuroimaging analysis</title>
      <link>https://jbourgin.github.io/project/multimodal/</link>
      <pubDate>Mon, 16 Mar 2020 10:53:18 +0100</pubDate>
      <guid>https://jbourgin.github.io/project/multimodal/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://jbourgin.github.io/project/multimodal/analysis.png&#34; alt=&#34;analysis&#34;&gt;
During my 
&lt;a href=&#34;https://jbourgin.github.io/project/emotional&#34;&gt;thesis work&lt;/a&gt;, I conducted analyses involving neuroimaging data (diffusion MRI, fMRI and MRI).&lt;/p&gt;
&lt;p&gt;To perform these analyses, I used scripts for data extraction from a large database, 
&lt;a href=&#34;http://adni.loni.usc.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ADNI&lt;/a&gt;, and used several tools such as 
&lt;a href=&#34;https://www.fil.ion.ucl.ac.uk/spm/software/spm12/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPM&lt;/a&gt;, 
&lt;a href=&#34;https://web.conn-toolbox.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Conn&lt;/a&gt;, 
&lt;a href=&#34;https://surfer.nmr.mgh.harvard.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Freesurfer&lt;/a&gt;, 
&lt;a href=&#34;https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FSL&lt;/a&gt;, 
&lt;a href=&#34;https://mrtrix.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MRtrix&lt;/a&gt;, 
&lt;a href=&#34;https://www.volbrain.upv.es/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;volBrain&lt;/a&gt;, 
&lt;a href=&#34;https://tractoflow-documentation.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TractoFlow&lt;/a&gt;, and 
&lt;a href=&#34;https://mriqc.readthedocs.io/en/stable/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MRIQC&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Based on what I learned, I am working on tutorials and user-friendly scripts that will soon be available on Github.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lexique</title>
      <link>https://jbourgin.github.io/project/lexique/</link>
      <pubDate>Mon, 16 Mar 2020 10:40:30 +0100</pubDate>
      <guid>https://jbourgin.github.io/project/lexique/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://jbourgin.github.io/project/lexique/logo.png&#34; alt=&#34;logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;Lexique is a web tool created by 
&lt;a href=&#34;https://psycho-usmb.fr/boris.new/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Boris New&lt;/a&gt; and 
&lt;a href=&#34;http://www.pallier.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Christophe Pallier&lt;/a&gt;, and available at 
&lt;a href=&#34;http://www.lexique.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lexique&lt;/a&gt;. It currently includes two main components.&lt;/p&gt;
&lt;h2 id=&#34;lexique&#34;&gt;Lexique&lt;/h2&gt;
&lt;p&gt;&lt;i&gt;Lexique&lt;/i&gt; is a database that provides, for 140,000 french words, various informations.
For instance, it can provide frequency of occurrence in various corpus, phonological representation, associated lemmas, number of syllables, grammatical category, and more.&lt;/p&gt;
&lt;h2 id=&#34;openlexicon&#34;&gt;Openlexicon&lt;/h2&gt;
&lt;p&gt;&lt;i&gt;Openlexicon&lt;/i&gt; regroups several lexical databases, including Lexique, providing additional information such as age of acquisition, reading time or concreteness.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Booguiiiii</title>
      <link>https://jbourgin.github.io/project/boogui/</link>
      <pubDate>Mon, 16 Mar 2020 10:20:54 +0100</pubDate>
      <guid>https://jbourgin.github.io/project/boogui/</guid>
      <description>&lt;p&gt;Boogui (named so after the great 
&lt;a href=&#34;https://baldursgate.fandom.com/wiki/Boo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Boo&lt;/a&gt;, who was always keen to &amp;ldquo;go for the eyes&amp;rdquo;) is a software dedicated to viewing and processing gaze data recorded with 
&lt;a href=&#34;https://www.sr-research.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EyeLink&lt;/a&gt; or 
&lt;a href=&#34;https://www.smivision.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SMI&lt;/a&gt; eye trackers.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jbourgin.github.io/img/boogui.png&#34; alt=&#34;Screenshot&#34;&gt;&lt;/p&gt;
&lt;p&gt;Boogui currently includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visualization of gaze data over time for each trial with target frames displayed&lt;/li&gt;
&lt;li&gt;A video view that plays back the trial with eye movements overlaid&lt;/li&gt;
&lt;li&gt;Filtering of SMI data based on fixation / saccade / blink parameters (e.g. duration). Compared to the default algorithm provided by SMI, it takes into account artifacts and allows to consider both dispersion and velocity for more accurate calculation of fixations.&lt;/li&gt;
&lt;li&gt;Output reports (.txt or .csv files) that can then be directly imported in statistical analysis packages such as Statistica or R for further processing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Boogui currently implements experiments conducted during a thesis work conducted by Jessica Bourgin:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Visual search&lt;/li&gt;
&lt;li&gt;Pro-saccade/anti-saccade&lt;/li&gt;
&lt;li&gt;Gaze-contingent&lt;/li&gt;
&lt;li&gt;Saccadic choice&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
